{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ideas\n",
    "\n",
    "- User features:\n",
    "    - `locale`\n",
    "    - `age`\n",
    "    - `gender`\n",
    "    - `days_on_app`\n",
    "    - `location`\n",
    "    - `timezone`\n",
    "    - `num_friends`\n",
    "- For monthly windows between 1 and 5 months ago calculate the following features:\n",
    "    - `num_invited` (as per the `event_attendees` table)\n",
    "    - `num_yes`\n",
    "    - `num_no`\n",
    "    - `num_maybe`\n",
    "    - `avg_event_start_hour`\n",
    "    - `modal_event_dow`\n",
    "    - `num_invites` (as per the `event_interest` table)\n",
    "    - `num_interested`\n",
    "    - `num_not_interested`\n",
    "    - `num_invited_and_interested`\n",
    "    - `num_invited_and_not_interested`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from torch_frame.utils import infer_df_stype\n",
    "\n",
    "import utils\n",
    "\n",
    "conn = duckdb.connect('event/event.db')\n",
    "%load_ext sql\n",
    "%sql conn --alias duckdb\n",
    "%config SqlMagic.displaycon=False\n",
    "%config SqlMagic.autopandas=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('event/user-attendance/feats.sql', 'r') as f:\n",
    "    # run once with train_labels and once with val_labels\n",
    "    template = f.read()\n",
    "\n",
    "# create train, val and test features\n",
    "# takes 1 - 5 mins\n",
    "for s in ['train', 'val', 'test']:\n",
    "    print(f'Creating {s} table')\n",
    "    query = utils.render_jinja_sql(template, dict(set=s, subsample=0))\n",
    "    conn.sql(query)\n",
    "    print(f'{s} table created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.validate_feature_tables('user_attendance', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql train_df <<\n",
    "from user_attendance_train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_df_stype(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.feature_summary_df(train_df.sample(20_000), 'target', classification=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "from torch_frame import TaskType, stype\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.gbdt import LightGBM\n",
    "\n",
    "from inferred_stypes import task_to_stypes\n",
    "from train_gbdt import TASK_PARAMS\n",
    "\n",
    "TASK = 'rel-event-user-attendance'\n",
    "\n",
    "task_params = TASK_PARAMS[TASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql val_df <<\n",
    "select * from user_attendance_val_feats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_stype = task_to_stypes[TASK].copy()\n",
    "del col_to_stype['title']\n",
    "del col_to_stype['last_review_summary']\n",
    "val_tf = Dataset(\n",
    "    val_df,\n",
    "    col_to_stype=col_to_stype,\n",
    "    target_col=task_params['target_col'],\n",
    ").materialize().tensor_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt = LightGBM(task_type=task_params['task_type'])\n",
    "gbdt.load(f'models/{TASK}_lgbm.json')\n",
    "pred = gbdt.predict(tf_test=val_tf).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(gbdt.model)\n",
    "\n",
    "sample = np.random.randint(0, len(val_tf), size=10_000)\n",
    "\n",
    "val_arr, _, _ = gbdt._to_lightgbm_input(val_tf[sample])\n",
    "shap_values = explainer.shap_values(val_arr, pred[sample])\n",
    "\n",
    "# TODO verify\n",
    "feat_names = val_tf.col_names_dict.get(stype.categorical, []) + val_tf.col_names_dict[stype.numerical]\n",
    "\n",
    "shap.summary_plot(shap_values, val_arr, plot_type='violin', max_display=30, feature_names=feat_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
